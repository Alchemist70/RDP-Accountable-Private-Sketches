PrivateSketch is presented as an RDP-accountable approach for sketch-based detection in federated learning that provides rigorous, certified links between sketch dimension, local-noise parameters, and detection power against Byzantine updates. PrivateSketch combines per-layer low-dimensional client sketches with local Gaussian perturbation (recorded for RÃ©nyi DP accounting) and an adaptive sensitivity allocator (APS+) that distributes privacy budget to maximize detection under a global RDP constraint.

The main technical contributions are: (i) tight, formal sensitivity bounds for random-projection and CountSketch-style sketches under local model updates; (ii) Chernoff-style tail-inversion theorems mapping sketch/noise parameters to certified detection probabilities for median+MAD detectors; (iii) an end-to-end RDP accounting pipeline that composes per-mechanism tuples into auditable final $(\varepsilon,\delta)$ reports; and (iv) APS+, a practical optimizer balancing per-client noise allocation under global privacy budgets.

Empirical evaluation on MNIST, Fashion-MNIST, and CIFAR-10 shows that PrivateSketch achieves superior detection-versus-privacy trade-offs compared to standard robust aggregators (median, trimmed mean, Krum) and baseline DP methods (DP-FedAvg, DP-SGD) across federated non-IID benchmarks. Evaluation is performed under label-flip, scaled-gradient, backdoor, and colluding Byzantine attacks; comprehensive per-run privacy traces and RDP smoke-grids are provided for independent verification.
